{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Excel file\n",
    "try:\n",
    "    data = pd.read_excel('ucsdball.xlsx')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Data Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Feature Engineering\n",
    "data['win'] = data['Win/Loss  (1 if UCSD wins, 0 if UCSD loses)']  \n",
    "data['point_diff'] = data['UCSD PTS: (Points)'] - data['OPPONONET PTS: (Points)']\n",
    "data['possessions'] = data['UCSD FGA'] - data['UCSD OR'] + data['UCSD TO: (Turnovers)'] + 0.475 * data['UCSD FTA']\n",
    "data['offensive_efficiency'] = data['UCSD PTS: (Points)'] / data['possessions']\n",
    "data['defensive_efficiency'] = data['OPPONONET PTS: (Points)'] / data['possessions']\n",
    "data['turnover_diff'] = data['UCSD TO: (Turnovers)'] - data['OPPONENT TO: (Turnovers)']\n",
    "\n",
    "# Rolling averages\n",
    "data['ucsd_points_rolling_avg'] = data['UCSD PTS: (Points)'].rolling(window=5, min_periods=1).mean()\n",
    "data['turnover_rolling_avg'] = data['UCSD TO: (Turnovers)'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Define features and target\n",
    "X = data[['UCSD PTS: (Points)', 'OPPONONET PTS: (Points)', 'point_diff', 'UCSD TO: (Turnovers)', \n",
    "          'Home/Away  (1 if home, 0 if away)', 'offensive_efficiency', 'defensive_efficiency', \n",
    "          'turnover_diff', 'ucsd_points_rolling_avg', 'turnover_rolling_avg']]\n",
    "y = data['win']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Model Selection & Hyperparameter Tuning\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'Neural Network': MLPClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for each model\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'Neural Network': {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'alpha': [0.0001, 0.001, 0.01]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    best_scores[name] = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model_name = max(best_scores, key=best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model Selected: {best_model_name}\")\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizing Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Loss', 'Win'], yticklabels=['Loss', 'Win'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC Curve\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]  # Get probability scores\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve - {best_model_name}')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Save the best model and scaler\n",
    "joblib.dump(best_model, \"best_basketball_model.pkl\")\n",
    "print(\"\\nBest Model saved as 'best_basketball_model.pkl'.\")\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nScaler saved as 'scaler.pkl'.\")\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Save model performance results\n",
    "results = {\n",
    "    \"best_model\": best_model_name,\n",
    "    \"accuracy\": accuracy * 100,\n",
    "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "    \"roc_auc\": roc_auc\n",
    "}\n",
    "\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Save confusion matrix\n",
    "cm_data = {\n",
    "    \"labels\": [\"Loss\", \"Win\"],\n",
    "    \"matrix\": cm.tolist()\n",
    "}\n",
    "\n",
    "with open(\"confusion_matrix.json\", \"w\") as f:\n",
    "    json.dump(cm_data, f, indent=4)\n",
    "\n",
    "print(\"\\nResults saved for web visualization!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
